{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Binary Classification Model\n",
    "## 1. Project Setup and Data Loading"
   ],
   "id": "e0e7a860c9de00d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import custom modules\n",
    "from src.data_preprocessing import DataLoader, DataPreprocessor, create_pipeline\n",
    "from src.models import BinaryClassifier, ModelTrainer, HyperparameterTuner\n",
    "from src.evaluation import ClassificationEvaluator, evaluate_model, compare_models\n",
    "from src.feature_engineering import FeatureCreator, FeatureSelector\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize data loader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Load diabetes dataset\n",
    "print(\"Loading Diabetes Dataset...\")\n",
    "df = loader.load_sklearn_dataset(\"diabetes\", save_raw=True)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ],
   "id": "89651fbc27500b23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Data EXploration and Analysis",
   "id": "7ce0720cc9bcd320"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display basic information about the dataset\n",
    "from src.data_preprocessing import get_dataset_info\n",
    "\n",
    "info = get_dataset_info(df)\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"  - Shape: {info['shape']}\")\n",
    "print(f\"  - Numeric columns: {info['numeric_columns']}\")\n",
    "print(f\"  - Missing values: {sum(info['missing_values'].values())}\")\n",
    "print(f\"  - Memory usage: {info['memory_usage_mb']:.2f} MB\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())"
   ],
   "id": "c03c2c95fc6597b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Covert to Binary Classification Problem",
   "id": "ce4178795df048d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert diabetes regression to binary classification\n",
    "# We'll create a binary target based on diabetes progression threshold\n",
    "threshold = df['target'].median()\n",
    "df['binary_target'] = (df['target'] > threshold).astype(int)\n",
    "\n",
    "print(f\"Threshold for binary classification: {threshold:.2f}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(df['binary_target'].value_counts())\n",
    "print(f\"Class balance: {df['binary_target'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Drop the original regression target\n",
    "df_binary = df.drop(columns=['target'])"
   ],
   "id": "fa272f71b56cbbb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Data Visualization",
   "id": "22a7e2f95438c875"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df_binary.drop(columns=['binary_target']).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot target distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=df_binary, x='binary_target')\n",
    "plt.title('Target Distribution')\n",
    "plt.xlabel('Class (0: Low Progression, 1: High Progression)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Feature distributions by class\n",
    "feature_cols = df_binary.drop(columns=['binary_target']).columns[:6]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    sns.boxplot(data=df_binary, x='binary_target', y=col, ax=axes[i])\n",
    "    axes[i].set_title(f'{col} by Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "66a429e73285dddf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Data Processing Pipeline",
   "id": "971819ef8978016e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply complete preprocessing pipeline\n",
    "X_train, X_test, y_train, y_test, preprocessor = create_pipeline(\n",
    "    df_binary,\n",
    "    target_column='binary_target',\n",
    "    handle_missing=True,\n",
    "    missing_strategy='mean',\n",
    "    encode_categorical=True,\n",
    "    scale_features=True,\n",
    "    scaling_method='standard',\n",
    "    remove_outliers=False,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training class distribution:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())"
   ],
   "id": "a8cda9282fc5ac44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Feature Engineering (Optional)",
   "id": "2b4e1861693a02ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create additional features if needed\n",
    "feature_creator = FeatureCreator()\n",
    "\n",
    "# Convert back to DataFrame for feature engineering\n",
    "X_train_df = pd.DataFrame(X_train, columns=[f'feature_{i}' for i in range(X_train.shape[1])])\n",
    "X_test_df = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(X_test.shape[1])])\n",
    "\n",
    "# Create interaction features\n",
    "X_train_enhanced = feature_creator.create_interaction_features(\n",
    "    X_train_df,\n",
    "    column_pairs=[('feature_0', 'feature_1'), ('feature_2', 'feature_3')],\n",
    "    operation='multiply'\n",
    ")\n",
    "\n",
    "# Apply same transformations to test set\n",
    "X_test_enhanced = feature_creator.create_interaction_features(\n",
    "    X_test_df,\n",
    "    column_pairs=[('feature_0', 'feature_1'), ('feature_2', 'feature_3')],\n",
    "    operation='multiply'\n",
    ")\n",
    "\n",
    "print(f\"Enhanced training set shape: {X_train_enhanced.shape}\")"
   ],
   "id": "43eb0bf78bc9cd4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Model Training - Single Model",
   "id": "f671435f527416d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train a single Random Forest classifier\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "rf_classifier = BinaryClassifier(\n",
    "    model_type='random_forest',\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "y_pred_proba_rf = rf_classifier.predict_proba(X_test)\n",
    "\n",
    "print(\"Random Forest training completed!\")"
   ],
   "id": "5b8f17d0880f566a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Model Training - Multiple Models",
   "id": "a9828e44cb321994"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train multiple models for comparison\n",
    "trainer = ModelTrainer(random_state=42)\n",
    "\n",
    "model_configs = {\n",
    "    'Random Forest': {\n",
    "        'model_type': 'random_forest',\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model_type': 'logistic_regression',\n",
    "        'C': 1.0\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model_type': 'svm',\n",
    "        'C': 1.0,\n",
    "        'kernel': 'rbf'\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model_type': 'gradient_boosting',\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Training multiple models...\")\n",
    "trained_models = trainer.train_multiple_models(X_train, y_train, model_configs)\n",
    "print(f\"Successfully trained {len(trained_models)} models\")"
   ],
   "id": "85c1468d0dfac3f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Hyperparameter Tuning",
   "id": "2608166c5a896b81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Tune Random Forest hyperparameters\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "base_model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "tuner = HyperparameterTuner(\n",
    "    model=base_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Use RandomizedSearchCV for faster tuning\n",
    "best_rf_model = tuner.random_search(X_train, y_train, n_iter=20, n_jobs=-1)\n",
    "\n",
    "print(f\"\\nBest parameters: {tuner.get_best_params()}\")\n",
    "print(f\"Best CV F1 score: {tuner.get_best_score():.4f}\")"
   ],
   "id": "7dd9a8e1d95fc114",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. Model Evaluation",
   "id": "9620fbad41b95f92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate all trained models\n",
    "print(\"Evaluating all models...\")\n",
    "results_df = compare_models(trained_models, X_test, y_test, average='weighted')\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Detailed evaluation of the best performing model\n",
    "best_model_name = results_df.index[0]\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(f\"\\nDetailed evaluation of {best_model_name}:\")\n",
    "evaluator = ClassificationEvaluator(model_name=best_model_name)\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)\n",
    "\n",
    "metrics = evaluator.evaluate(y_test, y_pred_best, y_pred_proba_best)\n",
    "\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ],
   "id": "2017bf7f6572139e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11. Visualization of Results",
   "id": "72c0097467cb6ee6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot confusion matrix\n",
    "fig_cm = evaluator.plot_confusion_matrix(\n",
    "    y_test, y_pred_best,\n",
    "    class_names=['Low Progression', 'High Progression'],\n",
    "    normalize=True,\n",
    "    figsize=(8, 6)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "fig_roc = evaluator.plot_roc_curve(\n",
    "    y_test, y_pred_proba_best[:, 1],\n",
    "    figsize=(8, 6)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "fig_pr = evaluator.plot_precision_recall_curve(\n",
    "    y_test, y_pred_proba_best[:, 1],\n",
    "    figsize=(8, 6)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Model comparison visualization\n",
    "metrics_dict = {name: evaluate_model(model, X_test, y_test, name)\n",
    "                for name, model in trained_models.items()}\n",
    "\n",
    "fig_comparison = evaluator.plot_metrics_comparison(\n",
    "    metrics_dict,\n",
    "    figsize=(12, 6)\n",
    ")\n",
    "plt.show()"
   ],
   "id": "fddee4dc42791bdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12. Feature Importance Analysis",
   "id": "2fb5dc49fc33c285"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Analyze feature importance for tree-based models\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    from src.models import get_feature_importance\n",
    "\n",
    "    feature_names = [f'feature_{i}' for i in range(X_train.shape[1])]\n",
    "    importance_df = get_feature_importance(best_model, feature_names)\n",
    "\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(importance_df.head(10))\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_features = importance_df.head(10)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 10 Feature Importances - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "3037cc7b29592c1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 13. Model Persistence",
   "id": "65a8feaab6a520e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the best model\n",
    "from src.models import save_model, load_model\n",
    "\n",
    "model_save_path = 'models/best_diabetes_classifier.pkl'\n",
    "save_model(best_model, model_save_path)\n",
    "\n",
    "# Save preprocessing pipeline\n",
    "import pickle\n",
    "with open('models/diabetes_preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "print(f\"Model and preprocessor saved successfully!\")\n",
    "\n",
    "# Demonstrate loading and using the saved model\n",
    "loaded_model = load_model(model_save_path)\n",
    "test_predictions = loaded_model.predict(X_test[:5])\n",
    "print(f\"Test predictions from loaded model: {test_predictions}\")"
   ],
   "id": "db56fefd370d3be5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 14. Cross-Validation Analysis",
   "id": "e6097ab3d2f61275"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform cross-validation on the best model\n",
    "from src.models import cross_validate_model\n",
    "\n",
    "cv_results = cross_validate_model(\n",
    "    best_model, X_train, y_train,\n",
    "    cv=5, scoring='f1'\n",
    ")\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"  Mean F1 Score: {cv_results['mean_score']:.4f}\")\n",
    "print(f\"  Standard Deviation: {cv_results['std_score']:.4f}\")\n",
    "print(f\"  Individual Scores: {cv_results['scores']}\")\n",
    "\n",
    "# Visualize CV scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(cv_results['scores'])\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Cross-Validation F1 Scores Distribution')\n",
    "plt.xticks([1], [best_model_name])\n",
    "plt.show()"
   ],
   "id": "67a2e3ebd7db1fde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 15. Prediction on New Data",
   "id": "ca7e1977f3f32c63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to make predictions on new data\n",
    "def predict_diabetes_progression(new_data, model_path='models/best_diabetes_classifier.pkl',\n",
    "                                preprocessor_path='models/diabetes_preprocessor.pkl'):\n",
    "    \"\"\"\n",
    "    Predict diabetes progression for new data.\n",
    "\n",
    "    Args:\n",
    "        new_data: DataFrame with same features as training data\n",
    "        model_path: Path to saved model\n",
    "        preprocessor_path: Path to saved preprocessor\n",
    "\n",
    "    Returns:\n",
    "        Predictions and probabilities\n",
    "    \"\"\"\n",
    "    # Load model and preprocessor\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    with open(preprocessor_path, 'rb') as f:\n",
    "        preprocessor = pickle.load(f)\n",
    "\n",
    "    # Preprocess new data (you'd need to implement this based on your pipeline)\n",
    "    # For now, assuming data is already preprocessed\n",
    "    predictions = model.predict(new_data)\n",
    "    probabilities = model.predict_proba(new_data)\n",
    "\n",
    "    return predictions, probabilities\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nExample prediction on test data:\")\n",
    "sample_data = X_test[:3]\n",
    "preds, probs = predict_diabetes_progression(sample_data)\n",
    "print(f\"Predictions: {preds}\")\n",
    "print(f\"Probabilities: {probs}\")"
   ],
   "id": "e6edf7cf60b7110f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
