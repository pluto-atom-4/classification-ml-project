{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Implement multiclass classification on the Iris dataset\n",
    "\n",
    "## 1. Import Required Libraries"
   ],
   "id": "a3220b5b712d2523"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import preprocessing and model modules\n",
    "from data_preprocessing import DataLoader, DataPreprocessor, create_pipeline\n",
    "from models import MulticlassClassifier, ModelTrainer, HyperparameterTuner\n",
    "from evaluation import ClassificationEvaluator, print_evaluation_summary\n",
    "from feature_engineering import FeatureSelector, DimensionalityReducer\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Load and Explore Data",
   "id": "61d3fd97228ce2f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "loader = DataLoader()\n",
    "df = loader.load_sklearn_dataset('iris', save_raw=True)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\\n{df.head()}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "print(f\"\\nClass distribution:\\n{df['target'].value_counts()}\")"
   ],
   "id": "c6ef0d86c30a593a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Data Preprocessing",
   "id": "b1d5926e82a09ea6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create preprocessing pipeline\n",
    "X_train, X_test, y_train, y_test, preprocessor = create_pipeline(\n",
    "    df,\n",
    "    target_column='target',\n",
    "    handle_missing=True,\n",
    "    missing_strategy='mean',\n",
    "    encode_categorical=True,\n",
    "    scale_features=True,\n",
    "    scaling_method='standard',\n",
    "    remove_outliers=False,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"\\nClass distribution in training set:\\n{pd.Series(y_train).value_counts().sort_index()}\")"
   ],
   "id": "da8132fbf2ff981d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Featyre Engineering",
   "id": "b0086efd05475462"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Feature selection\n",
    "selector = FeatureSelector()\n",
    "X_train_selected, selected_features = selector.select_k_best(\n",
    "    X_train, y_train, k=3\n",
    ")\n",
    "X_test_selected = X_test[:, selector.selector.get_support()]\n",
    "\n",
    "print(f\"Original features: {X_train.shape[1]}\")\n",
    "print(f\"Selected features: {len(selected_features)}\")\n",
    "print(f\"Feature names: {selected_features}\")"
   ],
   "id": "e6cfe37a6a6bd0d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Train Multiclass Models",
   "id": "7338d6085554bb74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train multiple multiclass models\n",
    "trainer = ModelTrainer(random_state=42)\n",
    "\n",
    "model_configs = {\n",
    "    'Random Forest': {\n",
    "        'model_type': 'random_forest',\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model_type': 'gradient_boosting',\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model_type': 'logistic_regression',\n",
    "        'max_iter': 1000\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model_type': 'knn',\n",
    "        'n_neighbors': 5\n",
    "    }\n",
    "}\n",
    "\n",
    "trained_models = trainer.train_multiple_models(X_train, y_train, model_configs)\n",
    "\n",
    "print(f\"Successfully trained {len(trained_models)} models\")\n",
    "for model_name in trained_models.keys():\n",
    "    print(f\"  âœ“ {model_name}\")"
   ],
   "id": "49dea28641edbce7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Hyperparameter Tuning",
   "id": "e3d62c7d5ea8dd01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Tune Random Forest hyperparameters\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    rf_model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "best_rf_model = tuner.grid_search(X_train, y_train, n_jobs=-1)\n",
    "\n",
    "print(f\"\\nBest parameters: {tuner.get_best_params()}\")\n",
    "print(f\"Best CV score: {tuner.get_best_score():.4f}\")"
   ],
   "id": "e08f3efa909db845",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Model Evaluation",
   "id": "f41b2d52faf4d6e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate best model on test set\n",
    "evaluator = ClassificationEvaluator(model_name='Tuned Random Forest')\n",
    "\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "y_pred_proba = best_rf_model.predict_proba(X_test)\n",
    "\n",
    "metrics = evaluator.evaluate(y_test, y_pred, y_pred_proba, average='weighted')\n",
    "\n",
    "print(\"Test Set Metrics:\")\n",
    "print(\"-\" * 40)\n",
    "for metric_name, value in metrics.items():\n",
    "    print(f\"  {metric_name:20s}: {value:.4f}\")"
   ],
   "id": "f7e052a369e04cad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Visualization - Confusion Matrix",
   "id": "f0177f02cab17b6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot confusion matrix\n",
    "fig = evaluator.plot_confusion_matrix(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    class_names=['Class 0', 'Class 1', 'Class 2'],\n",
    "    normalize=False,\n",
    "    figsize=(8, 6)\n",
    ")\n",
    "plt.show()"
   ],
   "id": "157599d61cc8ecae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. Visualization - Classification Report",
   "id": "f0634ff06c56a5a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print detailed classification report\n",
    "print_evaluation_summary(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    y_pred_proba,\n",
    "    model_name='Tuned Random Forest',\n",
    "    class_names=['Class 0', 'Class 1', 'Class 2']\n",
    ")"
   ],
   "id": "e91231e56930092c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. Compare All Models",
   "id": "4b81bbfc9c12b753"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare all trained models\n",
    "from src.evaluation import compare_models\n",
    "\n",
    "comparison_results = compare_models(\n",
    "    trained_models,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    average='weighted'\n",
    ")\n",
    "\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_results)"
   ],
   "id": "78a5fa528de72ccd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 11. Feature Importance",
   "id": "609f2bff0abe1d17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get feature importance from best model\n",
    "from src.models import get_feature_importance\n",
    "\n",
    "importance_df = get_feature_importance(\n",
    "    best_rf_model,\n",
    "    feature_names=['Feature 0', 'Feature 1', 'Feature 2', 'Feature 3']\n",
    ")\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Plot feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(data=importance_df, x='importance', y='feature', ax=ax)\n",
    "ax.set_title('Feature Importance - Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "bdb60aee39a0047a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 12. Save Best Model",
   "id": "a565e05b61b33996"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the best model\n",
    "from src.models import save_model\n",
    "\n",
    "save_model(best_rf_model, 'models/best_multiclass_model.pkl')\n",
    "print(\"Model saved successfully!\")"
   ],
   "id": "73a1228b663440f0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
