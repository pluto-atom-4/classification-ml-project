{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# 05_retrain_wine_multiclass.ipynb\\n\",\n",
    "    \"\\n\",\n",
    "    \"Retrain a multiclass classifier on the Wine dataset, compare simple models, and save the best-performing model to `models/best_wine_model.pkl`.\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook uses scikit-learn's built-in Wine dataset and demonstrates a minimal reproducible workflow: load data, preprocess (train/test split, scaling), train Logistic Regression and Random Forest, evaluate, plot a confusion matrix, and persist the best model with joblib.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Imports\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from sklearn.datasets import load_wine\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestClassifier\\n\",\n",
    "    \"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Ensure models directory exists\\n\",\n",
    "    \"os.makedirs('models', exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"RANDOM_STATE = 42\\n\",\n",
    "    \"TEST_SIZE = 0.2\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load dataset and quick EDA\\n\",\n",
    "    \"data = load_wine(as_frame=True)\\n\",\n",
    "    \"X = data.data\\n\",\n",
    "    \"y = data.target\\n\",\n",
    "    \"feature_names = list(X.columns)\\n\",\n",
    "    \"class_names = list(data.target_names)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('Features shape:', X.shape)\\n\",\n",
    "    \"print('Number of classes:', len(np.unique(y)))\\n\",\n",
    "    \"print('Class names:', class_names)\\n\",\n",
    "    \"print('\\nClass distribution:\\n', y.value_counts())\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train/test split and scaling\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "    \"    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n",
    "    \"X_test_scaled = scaler.transform(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define models to compare\\n\",\n",
    "    \"models = {\\n\",\n",
    "    \"    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\\n\",\n",
    "    \"    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"results = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for name, model in models.items():\\n\",\n",
    "    \"    print(f'--- Training {name} ---')\\n\",\n",
    "    \"    model.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"    preds = model.predict(X_test_scaled)\\n\",\n",
    "    \"    acc = accuracy_score(y_test, preds)\\n\",\n",
    "    \"    print(f'Accuracy: {acc:.4f}')\\n\",\n",
    "    \"    print(classification_report(y_test, preds, target_names=class_names))\\n\",\n",
    "    \"    results[name] = {'model': model, 'accuracy': acc, 'preds': preds}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select best model by accuracy\\n\",\n",
    "    \"best_name = max(results.keys(), key=lambda k: results[k]['accuracy'])\\n\",\n",
    "    \"best = results[best_name]\\n\",\n",
    "    \"print(f'Best model: {best_name} with accuracy {best[\"accuracy\"]:.4f}')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Confusion matrix for best model\\n\",\n",
    "    \"cm = confusion_matrix(y_test, best['preds'])\\n\",\n",
    "    \"plt.figure(figsize=(6,5))\\n\",\n",
    "    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\\n\",\n",
    "    \"            xticklabels=class_names, yticklabels=class_names)\\n\",\n",
    "    \"plt.xlabel('Predicted')\\n\",\n",
    "    \"plt.ylabel('True')\\n\",\n",
    "    \"plt.title(f'Confusion Matrix - {best_name}')\\n\",\n",
    "    \"plt.show()\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save the best model and the scaler\\n\",\n",
    "    \"model_path = os.path.join('models', 'best_wine_model.pkl')\\n\",\n",
    "    \"scaler_path = os.path.join('models', 'best_wine_scaler.pkl')\\n\",\n",
    "    \"joblib.dump(best['model'], model_path)\\n\",\n",
    "    \"joblib.dump(scaler, scaler_path)\\n\",\n",
    "    \"print(f'Saved best model to: {model_path}')\\n\",\n",
    "    \"print(f'Saved scaler to: {scaler_path}')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Quick load and predict demo\\n\",\n",
    "    \"loaded = joblib.load(model_path)\\n\",\n",
    "    \"loaded_scaler = joblib.load(scaler_path)\\n\",\n",
    "    \"sample = X_test.iloc[:5]\\n\",\n",
    "    \"sample_scaled = loaded_scaler.transform(sample)\\n\",\n",
    "    \"print('Sample predictions:', loaded.predict(sample_scaled))\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"The notebook trained two simple classifiers and saved the best-performing model. Next steps: hyperparameter tuning with GridSearchCV or RandomizedSearchCV, cross-validation, feature selection, and model interpretability analysis.\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.11\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n",
    "\n"
   ],
   "id": "c1d8a31f071ca723"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
