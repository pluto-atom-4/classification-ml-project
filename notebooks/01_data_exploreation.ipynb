{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 01 Data Exploration Notebook\n",
    " This notebook performs an initial exploration of a dataset, including loading, inspecting, and summarizing\n",
    " its features and target variable.\n"
   ],
   "id": "bf1f266fdaa0c359"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T18:06:57.867534Z",
     "start_time": "2025-11-14T18:06:57.863797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys"
   ],
   "id": "6428aa971fba1f34",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 1: Data Loading",
   "id": "c4a0d9eba3ed358"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:06:57.962195Z",
     "start_time": "2025-11-14T18:06:57.886401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from data_preprocessing import DataLoader\n",
    "\n",
    "# Initialize data loader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Load iris dataset\n",
    "df = loader.load_sklearn_dataset(\"iris\", save_raw=True)\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ],
   "id": "9b9e00d19eaed7a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to C:\\Users\\nobu\\PyCharmMiscProject\\data\\raw\\iris.csv\n",
      "Dataset loaded successfully!\n",
      "Dataset shape: (150, 5)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 2: Initial Data Inspection",
   "id": "93649170e6eb9724"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:06:58.094423Z",
     "start_time": "2025-11-14T18:06:57.973601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display first few rows\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ],
   "id": "cea6a9fc990e1393",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   target             150 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 6.0 KB\n",
      "None\n",
      "\n",
      "Basic statistics:\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            5.843333          3.057333           3.758000   \n",
      "std             0.828066          0.435866           1.765298   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.600000   \n",
      "50%             5.800000          3.000000           4.350000   \n",
      "75%             6.400000          3.300000           5.100000   \n",
      "max             7.900000          4.400000           6.900000   \n",
      "\n",
      "       petal width (cm)      target  \n",
      "count        150.000000  150.000000  \n",
      "mean           1.199333    1.000000  \n",
      "std            0.762238    0.819232  \n",
      "min            0.100000    0.000000  \n",
      "25%            0.300000    0.000000  \n",
      "50%            1.300000    1.000000  \n",
      "75%            1.800000    2.000000  \n",
      "max            2.500000    2.000000  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 3: Missing Values and Data Quality",
   "id": "57a4ab51b4088f84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:06:58.250441Z",
     "start_time": "2025-11-14T18:06:58.101826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data_preprocessing import get_dataset_info\n",
    "\n",
    "# Get comprehensive dataset information\n",
    "info = get_dataset_info(df)\n",
    "\n",
    "print(\"Data Quality Report:\")\n",
    "print(f\"  - Shape: {info['shape']}\")\n",
    "print(f\"  - Missing values: {sum(info['missing_values'].values())}\")\n",
    "print(f\"  - Duplicates: {info['duplicates']}\")\n",
    "print(f\"  - Memory usage: {info['memory_usage_mb']:.2f} MB\")\n",
    "\n",
    "print(\"\\nMissing values by column:\")\n",
    "for col, count in info['missing_values'].items():\n",
    "    print(f\"  {col}: {count}\")"
   ],
   "id": "49f5f3e4014bb4e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Report:\n",
      "  - Shape: (150, 5)\n",
      "  - Missing values: 0\n",
      "  - Duplicates: 1\n",
      "  - Memory usage: 0.01 MB\n",
      "\n",
      "Missing values by column:\n",
      "  sepal length (cm): 0\n",
      "  sepal width (cm): 0\n",
      "  petal length (cm): 0\n",
      "  petal width (cm): 0\n",
      "  target: 0\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 4: Feature Analysis",
   "id": "75d6b6902f545c6d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:06:58.383026Z",
     "start_time": "2025-11-14T18:06:58.296854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Feature Analysis:\")\n",
    "print(f\"  - Numeric columns: {info['numeric_columns']}\")\n",
    "print(f\"  - Categorical columns: {info['categorical_columns']}\")\n",
    "\n",
    "print(\"\\nNumeric columns summary:\")\n",
    "numeric_df = df[info['numeric_columns']]\n",
    "print(numeric_df.describe())\n",
    "\n",
    "if info['categorical_columns']:\n",
    "    print(\"\\nCategorical columns summary:\")\n",
    "    for col in info['categorical_columns']:\n",
    "        print(f\"  {col}: {df[col].nunique()} unique values\")"
   ],
   "id": "44304ab5d203aaea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Analysis:\n",
      "  - Numeric columns: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target']\n",
      "  - Categorical columns: []\n",
      "\n",
      "Numeric columns summary:\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            5.843333          3.057333           3.758000   \n",
      "std             0.828066          0.435866           1.765298   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.600000   \n",
      "50%             5.800000          3.000000           4.350000   \n",
      "75%             6.400000          3.300000           5.100000   \n",
      "max             7.900000          4.400000           6.900000   \n",
      "\n",
      "       petal width (cm)      target  \n",
      "count        150.000000  150.000000  \n",
      "mean           1.199333    1.000000  \n",
      "std            0.762238    0.819232  \n",
      "min            0.100000    0.000000  \n",
      "25%            0.300000    0.000000  \n",
      "50%            1.300000    1.000000  \n",
      "75%            1.800000    2.000000  \n",
      "max            2.500000    2.000000  \n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Block 5: Target Variable Distribution",
   "id": "dc93a3cbeaa4f836"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:06:58.509239Z",
     "start_time": "2025-11-14T18:06:58.421737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Analyze target variable distribution\n",
    "target_col = 'target'\n",
    "if target_col in df.columns:\n",
    "    print(f\"Target variable '{target_col}' distribution:\")\n",
    "    print(df[target_col].value_counts().sort_index())\n",
    "    print(f\"\\nClass distribution (%):\")\n",
    "    print((df[target_col].value_counts(normalize=True).sort_index() * 100).round(2))\n",
    "else:\n",
    "    print(\"No 'target' column found in dataset\")"
   ],
   "id": "9850153fe8f9ca42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable 'target' distribution:\n",
      "target\n",
      "0    50\n",
      "1    50\n",
      "2    50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution (%):\n",
      "target\n",
      "0    33.33\n",
      "1    33.33\n",
      "2    33.33\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Block 6: Data Exploration Summary",
   "id": "2fd4871dbeb2a062"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:06:58.639048Z",
     "start_time": "2025-11-14T18:06:58.531258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Dataset exploration completed!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  - Total samples: {df.shape[0]}\")\n",
    "print(f\"  - Total features: {df.shape[1]}\")\n",
    "print(f\"  - Data types: {df.dtypes.nunique()} unique types\")\n",
    "print(f\"  - Complete rows: {len(df.dropna())}\")\n",
    "print(\"=\"*60)"
   ],
   "id": "5855474ca2956f71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✓ Dataset exploration completed!\n",
      "============================================================\n",
      "\n",
      "Summary:\n",
      "  - Total samples: 150\n",
      "  - Total features: 5\n",
      "  - Data types: 2 unique types\n",
      "  - Complete rows: 150\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
